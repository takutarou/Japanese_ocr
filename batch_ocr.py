#!/usr/bin/env python3
"""
PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒƒãƒOCRå‡¦ç†ã‚¹ã‚¯ãƒªãƒ—ãƒˆ

input_files/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨PDFãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã—ã¦OCRå‡¦ç†ã‚’å®Ÿè¡Œã—ã€
çµæœã‚’ output/ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ä¿å­˜ã—ã¾ã™ã€‚
"""

import sys
import subprocess
import shutil
from pathlib import Path
from typing import List, Tuple
import argparse


def find_pdf_files(input_dir: Path) -> List[Path]:
    """æŒ‡å®šãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªå†…ã®å…¨PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
    pdf_files = list(input_dir.glob("*.pdf"))
    pdf_files.sort()  # ãƒ•ã‚¡ã‚¤ãƒ«åé †ã«ã‚½ãƒ¼ãƒˆ
    return pdf_files


def merge_and_rename_output_files(
    pdf_path: Path,
    output_dir: Path,
    format: str
) -> bool:
    """
    yomitokuãŒç”Ÿæˆã—ãŸãƒšãƒ¼ã‚¸ã”ã¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’1ã¤ã«ãƒãƒ¼ã‚¸ã—ã€ãƒªãƒãƒ¼ãƒ 

    Args:
        pdf_path: å…ƒã®PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        format: å‡ºåŠ›å½¢å¼ (md, json, html, csv)

    Returns:
        æˆåŠŸãƒ•ãƒ©ã‚°
    """
    try:
        # yomitokuãŒç”Ÿæˆã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        # ãƒ‘ã‚¿ãƒ¼ãƒ³: input_files_test1_p1.md, input_files_test1_p2.md ãªã©
        pattern = f"*{pdf_path.stem}_p*.{format}"
        generated_files = list(output_dir.glob(pattern))

        if not generated_files:
            print(f"  âš ï¸  ç”Ÿæˆãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {pattern}")
            return False

        # ãƒšãƒ¼ã‚¸ç•ªå·ã§ã‚½ãƒ¼ãƒˆï¼ˆ_p1, _p2, ...ï¼‰
        def get_page_number(file_path: Path) -> int:
            # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ _pN ã® N ã‚’æŠ½å‡º
            stem = file_path.stem
            if '_p' in stem:
                page_str = stem.split('_p')[-1]
                try:
                    return int(page_str)
                except ValueError:
                    return 0
            return 0

        generated_files.sort(key=get_page_number)

        # å…¨ãƒšãƒ¼ã‚¸ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’çµåˆ
        merged_content = []
        for file_path in generated_files:
            with open(file_path, 'r', encoding='utf-8') as f:
                content = f.read()
                merged_content.append(content)

        # ãƒãƒ¼ã‚¸ã—ãŸã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
        output_file = output_dir / f"{pdf_path.stem}.{format}"

        # CSVã®å ´åˆã¯ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®é‡è¤‡ã‚’å‰Šé™¤
        if format == 'csv' and merged_content:
            lines_list = [content.split('\n') for content in merged_content]
            # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ä¿æŒ
            header = lines_list[0][0] if lines_list[0] else ""
            all_lines = [header] if header else []

            # å„ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ˜ãƒƒãƒ€ãƒ¼ä»¥å¤–ã®è¡Œã‚’è¿½åŠ 
            for i, lines in enumerate(lines_list):
                if i == 0:
                    # æœ€åˆã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å…¨è¡Œè¿½åŠ 
                    all_lines.extend(lines[1:])
                else:
                    # 2ç•ªç›®ä»¥é™ã¯ãƒ˜ãƒƒãƒ€ãƒ¼ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if lines and lines[0] == header:
                        all_lines.extend(lines[1:])
                    else:
                        all_lines.extend(lines)

            final_content = '\n'.join(all_lines)
        else:
            # MD/JSON/HTMLã¯å˜ç´”ã«çµåˆï¼ˆæ”¹è¡Œ2ã¤ã§åŒºåˆ‡ã‚Šï¼‰
            final_content = '\n\n'.join(merged_content)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã«æ›¸ãè¾¼ã¿
        if format == 'csv':
            # CSVã¯UTF-8 BOMä»˜ãã§ä¿å­˜
            with open(output_file, 'w', encoding='utf-8-sig') as f:
                f.write(final_content)
        else:
            with open(output_file, 'w', encoding='utf-8') as f:
                f.write(final_content)

        # å…ƒã®åˆ†å‰²ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        for file_path in generated_files:
            file_path.unlink()

        return True

    except Exception as e:
        print(f"  âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒ¼ã‚¸ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def move_processed_file(pdf_path: Path, processed_dir: Path) -> bool:
    """
    å‡¦ç†å®Œäº†ã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’processed_filesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã«ç§»å‹•

    Args:
        pdf_path: å‡¦ç†ã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        processed_dir: å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»å‹•å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

    Returns:
        æˆåŠŸãƒ•ãƒ©ã‚°
    """
    try:
        # processed_filesãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒå­˜åœ¨ã—ãªã„å ´åˆã¯ä½œæˆ
        processed_dir.mkdir(parents=True, exist_ok=True)

        # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç§»å‹•ï¼ˆshutil.moveã‚’ä½¿ã†ã“ã¨ã§ã‚¯ãƒ­ã‚¹ãƒ‡ãƒã‚¤ã‚¹ã®ç§»å‹•ã«ã‚‚å¯¾å¿œï¼‰
        destination = processed_dir / pdf_path.name
        shutil.move(str(pdf_path), str(destination))
        return True

    except Exception as e:
        print(f"  âš ï¸  ãƒ•ã‚¡ã‚¤ãƒ«ç§»å‹•ã‚¨ãƒ©ãƒ¼: {e}")
        return False


def process_pdf(
    pdf_path: Path,
    output_dir: Path,
    format: str,
    processed_dir: Path,
    max_retries: int = 2
) -> Tuple[bool, str]:
    """
    å˜ä¸€PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’OCRå‡¦ç†

    Args:
        pdf_path: å‡¦ç†ã™ã‚‹PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        output_dir: å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        format: å‡ºåŠ›å½¢å¼ (md, json, html, csv)
        processed_dir: å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»å‹•å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
        max_retries: æœ€å¤§ãƒªãƒˆãƒ©ã‚¤å›æ•°

    Returns:
        (æˆåŠŸãƒ•ãƒ©ã‚°, ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸)
    """
    for attempt in range(max_retries + 1):
        try:
            # yomitoku CLIã‚³ãƒãƒ³ãƒ‰ã‚’å®Ÿè¡Œ
            cmd = [
                'yomitoku',
                str(pdf_path),
                '-f', format,
                '-o', str(output_dir)
            ]

            result = subprocess.run(
                cmd,
                capture_output=True,
                text=True,
                timeout=600  # 10åˆ†ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )

            if result.returncode == 0:
                # ç”Ÿæˆã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒ¼ã‚¸ï¼†ãƒªãƒãƒ¼ãƒ 
                merge_success = merge_and_rename_output_files(pdf_path, output_dir, format)
                if not merge_success:
                    return False, "ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒãƒ¼ã‚¸ã«å¤±æ•—ã—ã¾ã—ãŸ"

                # å‡¦ç†å®Œäº†ã—ãŸPDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’processed_filesã«ç§»å‹•
                move_success = move_processed_file(pdf_path, processed_dir)
                if not move_success:
                    print(f"  âš ï¸  PDFãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»å‹•ã«å¤±æ•—ã—ã¾ã—ãŸãŒã€OCRå‡¦ç†ã¯å®Œäº†ã—ã¦ã„ã¾ã™")

                return True, ""
            else:
                error_msg = result.stderr if result.stderr else result.stdout
                if attempt < max_retries:
                    print(f"  âš ï¸  ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}: {pdf_path.name}")
                else:
                    return False, error_msg

        except subprocess.TimeoutExpired:
            if attempt < max_retries:
                print(f"  âš ï¸  ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ - ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}: {pdf_path.name}")
            else:
                return False, "å‡¦ç†ãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸï¼ˆ10åˆ†è¶…éï¼‰"
        except Exception as e:
            if attempt < max_retries:
                print(f"  âš ï¸  ã‚¨ãƒ©ãƒ¼ - ãƒªãƒˆãƒ©ã‚¤ {attempt + 1}/{max_retries}: {pdf_path.name}")
            else:
                return False, str(e)

    return False, "ä¸æ˜ãªã‚¨ãƒ©ãƒ¼"


def main():
    # ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³å¼•æ•°ã®ãƒ‘ãƒ¼ã‚¹
    parser = argparse.ArgumentParser(
        description='input_files/ å†…ã®å…¨PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒãƒƒãƒOCRå‡¦ç†'
    )
    parser.add_argument(
        '-f', '--format',
        choices=['md', 'json', 'html', 'csv'],
        default='md',
        help='å‡ºåŠ›å½¢å¼ (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: md)'
    )
    parser.add_argument(
        '-i', '--input',
        default='input_files',
        help='å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: input_files)'
    )
    parser.add_argument(
        '-o', '--output',
        default='output',
        help='å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: output)'
    )
    parser.add_argument(
        '-p', '--processed',
        default='processed_files',
        help='å‡¦ç†æ¸ˆã¿ãƒ•ã‚¡ã‚¤ãƒ«ã®ç§»å‹•å…ˆãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª (ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: processed_files)'
    )

    args = parser.parse_args()

    # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹ã®è¨­å®š
    input_dir = Path(args.input)
    output_dir = Path(args.output)
    processed_dir = Path(args.processed)

    # å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®å­˜åœ¨ç¢ºèª
    if not input_dir.exists():
        print(f"âŒ ã‚¨ãƒ©ãƒ¼: å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {input_dir}")
        sys.exit(1)

    # å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ä½œæˆ
    output_dir.mkdir(parents=True, exist_ok=True)

    # PDFãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
    pdf_files = find_pdf_files(input_dir)

    if not pdf_files:
        print(f"âŒ PDFãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ: {input_dir}")
        sys.exit(1)

    print(f"ğŸ“ å…¥åŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {input_dir}")
    print(f"ğŸ“ å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {output_dir}")
    print(f"ğŸ“„ å‡ºåŠ›å½¢å¼: {args.format}")
    print(f"ğŸ“š å‡¦ç†å¯¾è±¡: {len(pdf_files)} ãƒ•ã‚¡ã‚¤ãƒ«")
    print("-" * 60)

    # ãƒãƒƒãƒå‡¦ç†
    failed_files = []

    for idx, pdf_path in enumerate(pdf_files, 1):
        print(f"[{idx}/{len(pdf_files)}] å‡¦ç†ä¸­: {pdf_path.name}")

        success, error_msg = process_pdf(pdf_path, output_dir, args.format, processed_dir)

        if success:
            print(f"  âœ… å®Œäº†: {pdf_path.name}")
        else:
            print(f"  âŒ å¤±æ•—: {pdf_path.name}")
            failed_files.append((pdf_path.name, error_msg))

    # çµæœã‚µãƒãƒªãƒ¼
    print("-" * 60)
    print(f"âœ¨ å‡¦ç†å®Œäº†!")
    print(f"  æˆåŠŸ: {len(pdf_files) - len(failed_files)} / {len(pdf_files)} ãƒ•ã‚¡ã‚¤ãƒ«")

    if failed_files:
        print(f"  å¤±æ•—: {len(failed_files)} ãƒ•ã‚¡ã‚¤ãƒ«")
        print("\nâŒ å‡¦ç†ã§ããªã‹ã£ãŸãƒ•ã‚¡ã‚¤ãƒ«:")
        for filename, error_msg in failed_files:
            print(f"  - {filename}")
            if error_msg:
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æœ€åˆã®1è¡Œã®ã¿è¡¨ç¤ºï¼ˆé•·ã™ãã‚‹å ´åˆï¼‰
                error_lines = error_msg.split('\n')
                print(f"    ç†ç”±: {error_lines[0][:100]}")
        sys.exit(1)
    else:
        print("  ğŸ‰ å…¨ã¦ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒæ­£å¸¸ã«å‡¦ç†ã•ã‚Œã¾ã—ãŸï¼")


if __name__ == "__main__":
    main()
